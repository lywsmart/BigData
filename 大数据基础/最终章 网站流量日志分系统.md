# 最终章 综合项目—网站流量日志分系统

​	本章将通过Hadoop生态体系技术实现[网站流量日志分析系统]()，来帮助读者学习大数据体系架构的开发流程，以及利用现有技术解决实际生活中遇到的问题。

​	本章的核心是在[掌握网站流量日志数据分析系统]()的业务流程的前提下，具备独立[分析日志数据]()，并利用[MapReduce]()技术将数据[提取]()出易于分析的数据结构，以及使用[Hive完成数据分析]()，计算出相关需求结果的能力。



## 9.1 系统概述

​	了解系统概述，能够说出本系统的[背景]()、[需求]()和[架构]()

### 9.1.1 系统背景介绍

​	近年来，随着社会的不断发展，人们对于[海量数据]()的[挖掘]()和[运用]()越来越重视，大数据的统计分析可以为企业决策者提供充实的依据。

​	例如，通过对某[网站日志数据统计分析]()，可以得出网站的日访问量，从而得出网站的受欢迎程度；通过对移动APP的下载数据量进行统计分析，可得出应用程序的受欢迎程度，可以通过不同维度进行更深层次的数据分析，为运营分析与推广决策提供可靠的[数据依据]()。



### 9.1.2 需求分析

​	在大数据开发中，通常首要任务是[明确分析目的]()，使开发人员能准确地根据具体的需求去过滤数据并通过大数据技术进行数据分析和处理，将处理结果以图表等可视化的形式展示出来。

​	本项目分析的数据主要是用户在2022年8月份访问网站时产生的日志数据，具体分为以下两点需求。

#### (1) 浏览量（PV）分析

​	[浏览量分析]()是指统计网站的页面被用户[浏览的次数]()，它是[衡量网站质量]()的重要指标。在日志数据中，每一条数据就代表了网站的页面被浏览一次。

​	本项目统计网站在2022年8月份每天的浏览量。

#### (2) 人均浏览页数分析

​	[人均浏览页面分析]()是指统计网站的页面被[每个用户平均浏览的次数]()，它可以反应出网站对用户的粘性程度。

​	[人均浏览页面分析]()是通过浏览量和用户数（[UV]()）这两个指标计算得出，计算公式为[浏览量/用户数]()。





### 9.1.3 系统架构

<img src="./最终章 网站流量日志分系统.assets/image-20231214162551573.png" alt="image-20231214162551573" />



​	根据网站流量日志数据分析系统的整体流程，可以将该系统的实现分为[数据采集]()、[数据预处理]()、[数据仓库开发]()、[数据分析]()、[数据导出]()和[数据可视化]()这6个步骤。



#### 第一步：数据采集

​	在网站流量日志数据分析系统中，数据采集是将[网站产生的日志数据]()通过[Flume采集到HDFS]()，这样做的目的是能够避免因网站产生的日志数据过多，影响服务器自身存储的问题。



#### 第二步：数据预处理

​	数据预处理是指在采集的日志数据被分析之前，利用[MapReduce程序对这些数据进行清洗]()，例如根据实际业务场景提取日志数据中的部分内容、对数据进行规范化处理等。



#### 第三步：数据仓库开发

​	数据预处理完后的[半结构化数据]()通常会加载到[Hive数据仓库]()中，然后创建相应的数据库和表与预处理后的结构化数据进行映射关联，这样后续就可以使用HiveQL语句对数据进行分析。



#### 第四步：数据分析

​	[数据分析]()是网站流量日志数据分析系统中的核心内容，即根据相关需求使用[HiveQL语句]()，对指定表中的数据[进行分析]()，得出各种[指标结果]()。



#### 第五步：数据导出

​	数据分析完成后得到的指标结果存在[Hive的表]()中，为了方便后续进行[数据可视化处理]()，一般需要将[Hive表中的数据导出到MySQL的数据表]()。



#### 第六步：数据可视化

​	数据可视化是利用[BI]()工具获取[MySQL]()中数据表的数据，并将数据以[图表]()的形式展现出来，这样能够直观、简洁的提供给网站管理者和运营者进行决策与分析。





## 9.2 准备工作 模拟数据来源

​	本项目主要通过编写Java程序[模拟Nginx服务生成日志数据]()，并将生成的日志数据写入到指定的日志文件中供Flume采集。

​	（[这一部分不用学习，直接用下发的Jar包！！！]()）



### 9.2.1 创建Maven项目

​	在IDEA创建一个名为[LogDataSource]()的Maven项目，创建包[com.lcvc.generate]()。

<img src="./最终章 网站流量日志分系统.assets/image-20231214170428829.png" alt="image-20231214170428829" style="zoom:67%;" />





### 9.2.2 实现Java程序

​	在包com.lcvc.generate下创建类[GenerateLog]()，[编写模拟Nginx服务生成日志数据的代码]()。

```java
package com.lcvc.generate;


import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.lang.reflect.Array;
import java.text.DateFormat;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.Locale;
import java.util.Random;
import java.util.concurrent.TimeUnit;

public class GenerateLog {

    // 获取想要得到的所有预定义的url地址。
    public static String[] url_paths = {
            "article/112.html",
            "article/113.html",
            "article/114.html",
            "article/115.html",
            "article/116.html",
            "article/117.html",
            "article/118.html",
            "article/119.html",
            "video/821",
            "tag/list"
    };


    // 生成IP地址
    public static String[] ip_splices =
            {"102","71","145","33","67","54","164","121"
            };


    // 生成状态码
    public static String[] status_codes = {"200","404","500"};


    // 随机生成IP地址
    public static String randomIp(){
        int ipNum;
        StringBuilder ip = new StringBuilder();
        for (int i=0; i<4; i++){
            ipNum = new Random().nextInt(Array.getLength(ip_splices));
            ip.append(".").append(ip_splices[ipNum]);
        }
        return ip.substring(1);
    }

    // 随机生成状态码
    public static String randomCode(){
        int codeNum = new Random().nextInt(Array.getLength(status_codes));
        return status_codes[codeNum];
    }

    // 随机生成
    public static String randomUrl(){
        int urlNum = new Random().nextInt(Array.getLength(url_paths));
        return url_paths[urlNum];
    }

    // 随机生成日期
    public static String getDate() throws ParseException {
        Random random = new Random();
        String date;
        DateFormat dateFormat =
                new SimpleDateFormat("dd/MMM/yyyy:HH:mm:ss", Locale.ENGLISH);
        String days = String.valueOf(random.nextInt(30)+1);
        String hour = String.valueOf(random.nextInt(24));
        String minute = String.valueOf(random.nextInt(60));
        String second = String.valueOf(random.nextInt(60));
        date = days + "/"
                + "Aug" + "/"
                + "2022" + ":"
                + hour + ":"
                + minute + ":"
                + second;
        Date parseDate = dateFormat.parse(date);
        return dateFormat.format(parseDate);
    }


    private static String generateLog() throws ParseException {
        return randomIp()
                + " "
                + "["
                + getDate()
                + "]"
                +" "
                +"\""
                + "GET /"
                + randomUrl()
                + " HTTP/1.1\""
                + " "
                + randomCode();

    }


    // 运行jar文件时，通过参数指定日志数据的输出目录，间隔1秒钟生成1条日志数据。
    public static void main(String[] args)
            throws InterruptedException, IOException, ParseException {

        String path = args[0];

        File file = new File(path);

        while (true){
            FileOutputStream fos = new FileOutputStream(file, true);
            String content = generateLog()+"\n";
            fos.write(content.getBytes());
            TimeUnit.SECONDS.sleep(1);
            fos.close();
        }
    }
}
```

​	

​	通过Idea进行打包（步骤略）

​	最终生成Jar包

<img src="./最终章 网站流量日志分系统.assets/image-20231214173947926.png" alt="image-20231214173947926" style="zoom:75%;" />





### 9.3.3 上传Jar包

​	将Jar上传到master的/opt/software文件夹

<img src="./最终章 网站流量日志分系统.assets/image-20231214174210560.png" alt="image-20231214174210560" />



### 9.3.4 创建日志目录

​	在虚拟机master的/opt/software/目录下新建/data/weblog目录，[用于存放日志文件](/data/weblog)，具体命令如下。

```shell
mkdir -p /opt/software/data/weblog
```

<img src="./最终章 网站流量日志分系统.assets/image-20231214174403225.png" alt="image-20231214174403225" />



### 9.3.5 测试jar文件

​	运行[LogDataSource.jar]()文件。

​	并指定日志数据写入到[/opt/software/data/weblog](/opt/software/data/weblog)目录下的[nginx.log](/opt/software/data/weblog)文件中。

​	执行命令

```shell
java -cp /opt/software/LogDataSource.jar \
com.lcvc.generate.GenerateLog \
/opt/software/data/weblog/nginx.log
```

<img src="./最终章 网站流量日志分系统.assets/image-20231214174847367.png" alt="image-20231214174847367" style="zoom:67%;" />





### 9.3.6 查看日志数据

​	开启一个新的虚拟机master窗口，

​	执行如下命令查看日志文件nginx.log中实时写入的日志数据。

```shell
tail -f /opt/software/data/weblog/nginx.log
```

<img src="./最终章 网站流量日志分系统.assets/image-20231214175056979.png" alt="image-20231214175056979" style="zoom:50%;" />





### 再学一招：用Shell脚本挂起JAR任务

​	如果必须要开启会话来保持模拟任务，会非常不方便，所以我们可以用[Shell脚本]()在后台挂起模拟数据的任务。

​	创建一个存放项目脚本的目录

```shell
mkdir -p /opt/software/bin
```

#### (1)编写Shell脚本

```shell
vi /opt/software/bin/startlog.sh
```

​	编写以下脚本

```shell
#!/bin/bash
# sh startlog.sh stop	关闭模拟程序
# sh startlog.sh start	启动模拟程序

# 设置Java运行时环境变量，确保java命令可用
export PATH=$PATH:/opt/software/bin

# 设置LogDataSource.jar文件的路径
JAR_FILE="/opt/software/LogDataSource.jar"

# 设置日志文件路径
LOG_FILE="/opt/software/bin/startlog.txt"

# 设置保存进程ID的文件路径
PID_FILE="/opt/software/bin/pid.txt"

start() {
  if [ -f "$PID_FILE" ]; then
    echo "LogDataSource.jar 已经在运行，进程ID：$(cat $PID_FILE)"
  else
    nohup java -cp "$JAR_FILE" com.lcvc.generate.GenerateLog /opt/software/data/weblog/nginx.log >> "$LOG_FILE" 2>&1 &
    echo $! > "$PID_FILE"
    echo "LogDataSource.jar 正在后台运行，进程ID保存在 $PID_FILE 中。"
  fi
}

stop() {
  if [ -f "$PID_FILE" ]; then
    PID=$(cat "$PID_FILE")
    kill $PID
    rm "$PID_FILE"
    echo "LogDataSource.jar 已经停止，进程ID：$PID"
  else
    echo "LogDataSource.jar 没有在运行。"
  fi
}

case "$1" in
  start)
    start
    ;;
  stop)
    stop
    ;;
  restart)
    stop
    start
    ;;
  *)
    echo "用法: $0 {start|stop|restart}"
    exit 1
    ;;
esac

exit 0

```

#### (2)授予脚本文件[可执行权限]()

```shell
chmod +x /opt/software/bin/startlog.sh
```

#### (3)启动脚本

```shell
/opt/software/bin/startlog.sh start
```

<img src="./最终章 网站流量日志分系统.assets/image-20231214190430871.png" alt="image-20231214190430871" style="zoom:50%;" />



​	通过JPS查看该进程

<img src="./最终章 网站流量日志分系统.assets/image-20231214190508772.png" alt="image-20231214190508772" style="zoom:67%;" />



## 9.3 模块一 数据采集

​	掌握数据采集，能够独立完成[Flume采集数据]()的操作

### 9.3.1 编写Flume采集方案

​	使用[Flume采集]()日志文件nginx.log中的日志数据，将采集的日志数据[写入到HDFS]()。

​	在虚拟机master中创建文件WebLog.conf，在该文件中指定采集方案。

```shell
vi $FLUME_HOME/job/WebLog.conf
```

​	编写采集方案

```python
a1.sources = r1
a1.sinks = k1
a1.channels = c1
# 指定source类型为Exec，用于监控文件nginx.log内数据的变化
a1.sources.r1.type = exec
a1.sources.r1.command = tail -f /opt/software/data/weblog/nginx.log
# 指定sink类型为HDFS Sink，将实时采集的日志数据写入HDFS的指定目录
a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path = /weblog/%y-%m-%d/%H-%M/
a1.sinks.k1.hdfs.filePrefix = lcvc-
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.useLocalTimeStamp = true
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```



### 9.3.2 Flume采集数据

​	接下来，[确保LogDataSource.jar文件处于运行状态]()下，根据指定的采集方案，在虚拟机master启动Agent，采集日志文件nginx.log中的日志数据。

```shell
flume-ng agent \
--name a1 \
--conf $FLUME_HOME/job/ \
--conf-file $FLUME_HOME/job/WebLog.conf \
 -Dflume.root.logger=INFO,console
```



<img src="./最终章 网站流量日志分系统.assets/image-20231214191136053.png" alt="image-20231214191136053" />



​	通过HDFS的Web UI查看[/weblog/](/weblog/)目录中的内容。

​	([注意：时间是实时的]())

<img src="./最终章 网站流量日志分系统.assets/image-20231214191413438.png" alt="image-20231214191413438" />

​	



### 再学一招：用Shell脚本挂起Flume任务

​	如果必须要开启会话来保持模拟任务，会非常不方便，所以我们可以用[Shell脚本]()在后台挂起Flume采集数据的任务。

#### (1)编写Shell脚本

```shell
vi /opt/software/bin/startflume.sh
```

​	编写以下脚本

```shell
#!/bin/bash
# sh startflume.sh stop	关闭模拟程序
# sh startflume.sh start 启动模拟程序

# 设置Flume的根目录
export FLUME_HOME=/usr/local/src/flume

# Flume任务命令
FLUME_COMMAND="flume-ng agent \
  --name a1 \
  --conf $FLUME_HOME/job/ \
  --conf-file $FLUME_HOME/job/WebLog.conf \
  -Dflume.root.logger=INFO,console"

# 设置日志文件路径
LOG_FILE="/opt/software/bin/flume.log"

# 设置保存进程ID的文件路径
PID_FILE="/opt/software/bin/flume.pid"

start() {
  if [ -f "$PID_FILE" ]; then
    echo "Flume任务已经在运行，进程ID：$(cat $PID_FILE)"
  else
    nohup $FLUME_COMMAND >> "$LOG_FILE" 2>&1 &
    echo $! > "$PID_FILE"
    echo "Flume任务正在后台运行，进程ID保存在 $PID_FILE 中。"
  fi
}

stop() {
  if [ -f "$PID_FILE" ]; then
    PID=$(cat "$PID_FILE")
    kill $PID
    rm "$PID_FILE"
    echo "Flume任务已经停止，进程ID：$PID"
  else
    echo "Flume任务没有在运行。"
  fi
}

case "$1" in
  start)
    start
    ;;
  stop)
    stop
    ;;
  restart)
    stop
    start
    ;;
  *)
    echo "用法: $0 {start|stop|restart}"
    exit 1
    ;;
esac

exit 0

```

#### (2)授予脚本文件[可执行权限]()

```shell
chmod +x /opt/software/bin/startflume.sh
```

#### (3)启动脚本

```shell
/opt/software/bin/startflume.sh start
```



​	通过ps查看该进程

```shell
ps aux | grep flume
```

<img src="./最终章 网站流量日志分系统.assets/image-20231214192529656.png" alt="image-20231214192529656" style="zoom:67%;" />
